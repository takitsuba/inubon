{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 目次\n",
    "* はじめに\n",
    "    * 例：天気\n",
    "* 5.1. ベイズの公式¶\n",
    "    * 5.1.1. 条件付き確率の定義から導出されるもの\n",
    "    * 5.1.2. 2次元分割表から直感的にわかるベイズの公式\n",
    "        * 例：目の色、髪の色\n",
    "        * 例：病気の診断\n",
    "* 5.2. パラメータとデータへの適用\n",
    "* 5.2.1. データの順序の不変性\n",
    "* 5.3. コインのバイアスを推定する\n",
    "    * 例：コイントス\n",
    "* 5.3.1. 事後分布でのサンプルの大きさの影響\n",
    "* 5.3.2. 事後分布における事前分布の影響\n",
    "* 5.4. なぜベイズ推論が難しいのか\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# はじめに\n",
    "* ベイズの公式は、確信度を事前に割り当てることと、データにおける条件付きの事後的な再割り当てとの、数学的関係\n",
    "    * 例：天気についての2つの質問\n",
    "        * 「東京が雲がある（曇っている）確率はどれくらいか？」\n",
    "        * 「では、東京で雨が降っているが、雲がある確率はどれくらいか？」\n",
    "    * 下記のように推論した\n",
    "        1. 雲があるか、晴れているかについて、事前の確信度を持った\n",
    "        2. 他のデータ(雨が降っている）を考慮した\n",
    "        3. 新たなデータ（雨が降っている）の元で、天気の状態に確信度を割り当てた\n",
    "* 補足：日本だと天気を「晴れ・くもり・雨」と分類すると思うが、この例では天気を「晴れ・くもり」と分類し、「雨」は1つの現象と捉えている？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5.1. ベイズの公式\n",
    "* Thomas Bayes(1702-1761)\n",
    "* 頻度主義\n",
    "    * 推定や決定にベイズの公式を用いない流派\n",
    "    * Ronald Fisher(1890-1962)\n",
    "* 20世紀においてはフィッシャー的アプローチが優勢だったが、21世紀では18世紀に起源のあるベイジアン・アプローチが優勢\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.1.1. 条件付き確率の定義から導出されるもの\n",
    "* 条件付き確率の直感的な定義\n",
    "$$\n",
    "p(c|r) = \\frac {p(r,c)}{p(r)}\n",
    "$$\n",
    "* $r$(目の色)が与えられた時の$c$(髪の色)の確率は、$r$が生じる確率に対して、$r$と$c$が同時に生じた確率である。\n",
    "* この式を起点として、ベイズの公式を導出する。\n",
    "* 式の変形を行なっていく。両辺に$p(r)$をかけると下記。\n",
    "$$\n",
    "p(c|r)p(r) = p(r,c)\n",
    "$$\n",
    "* また、$p(r|c)=\\frac {p(r,c)}{p(c)}$という定義(rとcを入れ替えた)から始めて、上と同様の操作を行うと下記。\n",
    "$$\n",
    "p(r|c)p(c) = p(r,c)\n",
    "$$\n",
    "* 上2つの式は右辺が$p(r,c)$で同じ。そのため、下記。\n",
    "$$\n",
    "p(c|r)p(r) = p(r|c)p(c)\n",
    "$$\n",
    "+ 両辺を$p(r)$で割ると、\n",
    "$$\n",
    "p(c|r) = \\frac {p(r|c)p(c)}{p(r)}\n",
    "$$\n",
    "+ 分母$p(r)$は下記のように表せる。\n",
    "$$\n",
    "p(r) = \\sum_{c^*} p(r,c^*)\n",
    "= \\sum_{c^*} p(r|c^*)p(c^*)\n",
    "$$\n",
    "+ よって、\n",
    "$$\n",
    "p(c|r) = \\frac {p(r|c)p(c)}{\\sum_{c^*} p(r|c^*)p(c^*)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ 「ベイズの公式」は、上に出てきた式のうち、下記の2つ\n",
    "$$\n",
    "p(c|r) = \\frac {p(r|c)p(c)}{p(r)}\n",
    "$$\n",
    "$$\n",
    "p(c|r) = \\frac {p(r|c)p(c)}{\\sum_{c^*} p(r|c^*)p(c^*)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.1.2. 2次元分割表から直感的にわかるベイズの公式\n",
    "+ 補足：p.107 表5.4 の上から2行目検査結果の\n",
    "  * $\\theta = :)$\n",
    "  * $\\theta=:($\n",
    "  * は逆では？\n",
    "+ ベイズの公式\n",
    "$$\n",
    "p(c|r) = \\frac {p(r|c)p(c)}{\\sum_{c^*} p(r|c^*)p(c^*)}\n",
    "$$\n",
    "+ 表5.1\n",
    "<img src=\"./img/table5_1.png\">\n",
    "+ わかっている行の値に対する条件付き確率化は、既知の値が真である行にのみ限定的に注目し、その行の合計確率で割ることによる<font color=\"Red\">確率の正規化</font>であることが、鍵となる考え方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ 具体例1：目の色と髪の色\n",
    "+ 目の色と髪の色の様々な組み合わせの同時確率と周辺確率を示したもの\n",
    "+ 表5.2\n",
    "<img src=\"./img/table5_2.png\">\n",
    "+ ランダムに選ばれた人の目の色が青だとわかれば、この人は「青」の行に属するとわかり、そこに焦点を合わせることができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ 表5.3\n",
    "<img src=\"./img/table5_3.png\">\n",
    "+ 目の色を知る前の髪の色に関する「事前の」（周辺）信念から、観測された目の色の時の髪の色に関する「事後」（条件付き）信念に変化した（ブロンド:0.21→0.45)\n",
    "+ 行の値に関する情報（目の色）を与えられた時の列の値（髪の色）の<font color=\"Red\">確信度の条件付き再割り当て</font>を示している\n",
    "+ ただこの例では、同時確率$p(r,c)$を直接算出した数値にして使っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ 具体例2：珍しい病気の診断 p107\n",
    "+ 表5.4\n",
    "<img src=\"./img/table5_4.png\">\n",
    "+ T=+ :検査結果陽性、T=-:検査結果陰性。検査結果は病気のパラメータの値に関する信念を修正するのに用いる\n",
    "+ 的中率99%:病気なら、99%の確率で検査結果が陽性$p(T=+|\\theta =:(  )=0.99$\n",
    "+ フォールスアラーム率5%:病気でないのに、病気だと誤って示す確率$p(T=+|\\theta =:)  )=0.05$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 問題：母集団からランダムに人をサンプリング。検査を行い陽性だった時、その人が病気である事後確率は？$p(\\theta =:(|T=+)$\n",
    "* 直感だと、的中率と同程度のように思える（99%)\n",
    "+ 表5.4(同上)\n",
    "<img src=\"./img/table5_4.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 事前の信念\n",
    "+ 表の最下部に、病気に罹患している背景確率が記載されており、$p(:()=0.001$。病気でない確率は$p(:))=1-0.001=0.999$。\n",
    "+ 検査結果についての情報がなければ、この周辺確率が事前の信念。 \n",
    "\n",
    "### 同時確率\n",
    "+ 検査が陽性、病気に罹患している同時確率は表の左上\n",
    "+ $p(T=+,\\theta=:()=p(T=+|\\theta=:()\\times p(\\theta=:()= 0.99\\times 0.001$\n",
    "+ 検査が陽性になり病気に罹患している同時確率＝検査の的中率$\\times$病気の基礎率\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 改めて問題(事後確率)\n",
    "* 問題：母集団からランダムに人をサンプリング。検査を行い陽性だった時、その人が病気である事後確率は？$p(\\theta=:(|T=+)$\n",
    "+ $T=+$とマークされている行に着目すると、\n",
    "$$\n",
    "p(\\theta=:(|T=+) = \\frac {p(T=+|\\theta=:()\\times p(\\theta=:()}{\\sum_{\\theta} p(T=+|\\theta)p(\\theta)}\\\\\n",
    "= \\frac{0.99\\times0.001}{0.99\\times0.001+0.05\\times(1-0.001)}\\\\\n",
    "= 0.019\n",
    "$$\n",
    "+ つまり、99%の的中率である検査の結果が陽性でも、病気に罹患している事後確率は1.9%。\n",
    "+ これは、病気の事前確率が低く(罹患してない事前確率が高く）、検査のフォールスアラーム率が高いため。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## まとめ\n",
    "+ 病気の有無の事前確信度を見た(事前確率)。\n",
    "+ 検査結果を元に、行(検査結果ごと)に注意を向け、ベイズの公式によって行における病気の有無の条件付き確率を算出した(事後分布)。\n",
    "    + 条件付き確率は、得られたデータ(検査結果)に基づいて病気の有無に対して再割り当てされた確信度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.2. パラメータとデータへの適用 p109\n",
    "+ ベイズの公式を有効に使えるのは、行の変数がデータ値、列の変数がパラメータ値を表している場合\n",
    "<img src=\"./img/table5_5.png\">\n",
    "+ ベイズの公式は、特定のデータの行において、事前（パラメータ値の周辺分布)から事後(パラメータ値の条件付き分布)に注意を移させる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ベイズの公式の因数の名称\n",
    "$$\n",
    "p(\\theta|D) = \\frac {p(D|\\theta) p(\\theta)} {p(D)}\n",
    "$$\n",
    "* $p(\\theta|D)$:事後確率(データDを考慮に入れたθ値の確信度)\n",
    "* $p(D|\\theta)$:尤度(パラメータ値θのあるモデルによって生じるデータの確率\n",
    "+ $p(\\theta)$:事前確率(データDなしのθ値の確信度)\n",
    "+ $p(D)$:エビデンスor周辺尤度(モデルに関するデータDの全確率)\n",
    "    + $\\theta$の事前確率によって重みづけられた全ての$\\theta$の値を通して、尤度の平均$p(D|\\theta)$をとる操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.2.1. データの順序の不変性(p111)\n",
    "+ 問題：あるデータ$D$を考慮する場合、事前信念$p(\\theta)$から事後信念$p(\\theta|D)$を得ることができる。さらに$D'$を観測したとする。それによって、信念を$p(\\theta|D)$から$p(\\theta|D',D)$に更新できた。この時、$D$,$D'$の更新の順番によって、信念は左右されるか？\n",
    "+ 答え：左右されるかどうかは、特に尤度$p(D|\\theta)$を定義するモデルの関数次第。\n",
    "+ データの確率が独立している場合($p(D,D'|\\theta)=p(D|\\theta)\\times p(D'|\\theta)$)はデータの順序は関係ない。\n",
    "+ 本書の全ての例では、独立なデータを生成する数学的な尤度関数を用いている。\n",
    "+ (間違えてたらご指摘ください)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3. コインのバイアスを推定する\n",
    "+ 例：コイントス\n",
    "+ バイアス：表が出る確率。表が出やすいことを、「表にバイアスされている」ということもある。\n",
    "\n",
    "### ベイジアン分析のステップ(p24 2.3.)\n",
    "1. データの見極め\n",
    "2. モデルの定義\n",
    "3. パラメータの事前分布の設定\n",
    "4. パラメータに確信度を再分配\n",
    "5. 事後予測とデータの照らし合わせ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. データの見極め(p112 下から16行目)\n",
    "+ コイントス\n",
    "+ 投げた結果をy。表を1、裏を0。\n",
    "\n",
    "### 2. モデルの定義(p112 下から8行目)\n",
    "+ 意味のあるパラメータを持つ記述的モデルを作る。\n",
    "+ 表が出る確率を$p(y=1)$とする。\n",
    "+ 表の確率をパラメータ値$\\theta$であらわす。\n",
    "+ $p(y=1|\\theta) = \\theta$\n",
    "    + 「パラメータ値θが与えられた時、結果が表になる確率」\n",
    "+ 表と裏の確率の式を1つの式にする。\n",
    "    + $p(y|\\theta) = \\theta^y(1-\\theta)^{(1-y)}$\n",
    "+ 複数回コイントスした結果に関する尤度の式は下記。\n",
    "    + $p(\\{y_i\\}|\\theta)= \\prod_i p(y_i|\\theta)=\\theta^{front}(1-\\theta)^{back}$\n",
    "    + $front$は表の回数、$back$は裏の回数\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. パラメータの事前分布の設定(p113 下から9行目)\n",
    "+ パラメータ値の事前分布を確立していく。\n",
    "+ この例では、非現実的であるが、$\\theta$は0.0,0.1,0.2,...,1.0の11個しか取り得ないものとしている。\n",
    "+ 事前分布は、工場で製造されているコインのタイプについての、私たちの信念を示すもの。\n",
    "    + $\\theta$が0.5付近のコインを作ると仮定し、$\\theta=0.5$の上下のバイアスには低い事前確信度を割り当てる。\n",
    "    + 図5.1. 上段\n",
    "+ 図5.1.\n",
    "<img src=\"./img/fig5_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. パラメータに確信度を再分配(p114 下から6行目)\n",
    "#### モチベーション\n",
    "+ パラメータ値$\\theta$の事前分布は私たちの仮説にすぎない。\n",
    "+ このパラメータ値に確信度を再割り当てしたい。\n",
    "+ そのためにデータを集め、ベイズの公式に適用する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 再分配\n",
    "+ コインを1回投げて表が出たとする(N=1のとき、z(表の回数)=1)。これをデータ$D$とする。\n",
    "\n",
    "##### 尤度関数\n",
    "+ 先ほど、尤度関数は $p(y|\\theta) = \\theta^y(1-\\theta)^{(1-y)}$とした。\n",
    "+ データの尤度関数は$p(D|\\theta)=\\theta$となる。\n",
    "    + これをグラフにしたのが図5.1.中段。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 事後確率を計算してみる\n",
    "+ $\\theta=0.2$のときの事後確率は下記で求まる。\n",
    "    + 事前確率：$p(\\theta=0.2)= 0.08$\n",
    "    + 尤度：$p(\\theta=0.2|D)=0.2$\n",
    "    + エビデンス:\n",
    "    $$\n",
    "    p(D)=\\sum_{\\theta^*} p(D|\\theta^*)p(\\theta^*)= (0\\times0)+(0.04 \\times 0.1)+ (0.08 \\times 0.2)+... = 0.5\n",
    "    $$\n",
    "    + 事後確率：\n",
    "    $$\n",
    "    p(\\theta=0.2|D)= \\frac {p(D|\\theta) p(\\theta)} {p(D)} = \\frac {0.08 \\times 0.2} {0.5} = 0.032 \n",
    "    $$\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 事後分布\n",
    "+ 事後分布は図5.1.下段\n",
    "    + 事前分布で$p(\\theta=0.4)$と$p(\\theta=0.6)$が同じでも、事後分布では$p(\\theta=0.4|D)$は$p(\\theta=0.6|D)$より小さくなっている。\n",
    "    + 事前分布が事後分布に大きな残存効果を与えている。\n",
    "        + コインを1回しか投げてないから。\n",
    "            + 表の割合が100%でも、$\\theta$の値が大きい$p(\\theta=0.9|D)$などは低いまま。\n",
    "        + 事後分布の形も、事前分布の形に似ている。\n",
    "    + 事後分布は事前分布と尤度関数の折衷したもの\n",
    "        + 事前分布の範囲が尖った形、データ少ない\n",
    "            + 事前分布を支持する\n",
    "        + 事前分布が平坦、データ多い\n",
    "            + 尤度関数（データ）を支持する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.3.1. 事後分布でのサンプルの大きさの影響(p115)\n",
    "+ $\\theta$の候補を増やし、0.000,0.001,0.002,...,1.000までの、1001の候補があるとする。\n",
    "+ 左の例はz=1,N=4(表の割合25%)、右の例はz=10,N=40(表の割合25%)\n",
    "+ 図5.2.\n",
    "<img src=\"./img/fig5_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 事前分布$p(\\theta)$\n",
    "+ どちらも$\\theta=0.5$が最も高くなる三角形の事前分布\n",
    "\n",
    "#### 尤度関数$p(D|\\theta)$\n",
    "+ どちらも$\\theta=0.25$で最大となる。\n",
    "\n",
    "#### 事後分布$p(\\theta|D)$\n",
    "+ 左の例(サンプルサイズが小さい)\n",
    "    + 事後分布のピークは$\\theta=0.40$\n",
    "        + 尤度関数のピーク($0.25$)より事前分布のピーク($0.5$)に近い\n",
    "    + 事後最高密度区間の幅は$0.681-0.098=0.583$\n",
    "    \n",
    "+ 右の例(サンプルサイズが大きい)\n",
    "    + 事後分布のピークは$\\theta=0.268$\n",
    "        + 事前分布のピーク($0.5$)より尤度関数のピーク($0.25$)に近い\n",
    "    + 事後最高密度区間の幅は$0.412-0.151=0.261$\n",
    "    \n",
    "+ つまり、サンプルサイズが大きいほど、\n",
    "    + 事後分布のピークは尤度関数のピークに近くなる。\n",
    "    + 事後最高密度区間の幅は狭くなる。(推定が正確になる。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.3.2. 事後分布における事前分布の影響(p116)\n",
    "+ 5.3.1.の例を元に、事前分布を変更する。\n",
    "+ 左の例\n",
    "    + 事前分布をとても平らにする。\n",
    "    + すると、サンプルサイズは少ないのに、事後分布が尤度関数に非常に似た形になっている。\n",
    "    + 事前分布が尤度関数よりも比較的広い場合は、事前分布は事後分布にほとんど影響力を持たない。\n",
    "+ 右の例\n",
    "    + 事前分布を鋭くしている。\n",
    "    + すると、サンプルサイズが多いのに、事後分布は事前分布に影響を受けている。\n",
    "    + 強い事前知識がある場合、それと反するデータが与えられても、すぐには認識を改めない、ということかな。\n",
    "+ 図5.3.\n",
    "<img src=\"./img/fig5_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "+ ベイズ推論は直感的な推論\n",
    "    + 強い情報のある事前分布を用いれば、事前分布から少しでも信念を動かすには、多くの新しい反証データが必要\n",
    "    + あまり情報を与えない事前分布であれば、事後分布のピークを動かすには多くのデータを必要としない。\n",
    "+ 実際の調査で選ばれる事前分布\n",
    "    + データのスケールに対し、広くあまり影響しないような事前分布\n",
    "    + 公的に合意を得ている先行研究による情報を持った事前分布\n",
    "+ 情報を与えられた事前分布で始めることは有利で合理的。利用可能な時に使わないのは誤ちを犯す。\n",
    "    + 病気の診断ケースでは事前に病気の確率がわかっていた(p107)\n",
    "+ 事前の信念はデータからの合理的推論に影響を与える**はず**\n",
    "+ 新たなデータの役割は、新たなデータのない場合の信念を修正すること\n",
    "    + 事前の信念は変化しにくいものではない\n",
    "    + 公に合意を得られた要因や理論に基づいている\n",
    "+ 事前の信念について共通の認識が取れない場合\n",
    "    + いくつもの事前分布で分析\n",
    "    + いくつもの事前分布を同時分布としてミックス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.4. なぜベイズ推論が難しいのか(p118)\n",
    "+ ベイズの公式から事後分布を決定するには、エビデンス(周辺尤度)を計算する必要。\n",
    "$$\n",
    "p(D)=\\sum_{\\theta^*} p(D|\\theta^*)p(\\theta^*)\n",
    "$$\n",
    "$$\n",
    "p(D)=\\int d\\theta^* p(D|\\theta^*)p(\\theta^*)\n",
    "$$\n",
    "+ しかし、連続パラメータである場合、積分を解析的に導くのが不可能。\n",
    "+ 解決策\n",
    "    1. 共役事前分布\n",
    "    2. 変分近似\n",
    "    3. 積分の数値近似\n",
    "    4. 事後分布から代表的なパラメータ値の組み合わせを多数ランダムにサンプリングする\n",
    "        + MCMCのようなアルゴリズム\n",
    "        + ベイズの公式での積分を算出することなしに、複雑なモデルの事後分布から、パラメータ値の組み合わせを発生させることができる。    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 参考資料\n",
    "* プレゼンにはRISEというJupyter Notebookの拡張機能を用いています。\n",
    "    * [Jupyter Notebookでプレゼンをするとっても便利な方法](http://qiita.com/cvusk/items/d425751ba663dc8c6517)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
